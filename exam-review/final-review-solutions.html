<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="dcterms.date" content="2022-05-01" />
  <title>Math 51 Spring 2022 - Final Exam - some review problems Solutions</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
  </style>
  <link rel="stylesheet" href="/home/george/Classes/math51-spring2022/assets/default.css" />
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  
</head>
<body>
<header id="title-block-header">
<h1 class="title"><p>Math 51 Spring 2022 - Final Exam - some review problems <strong>Solutions</strong></p></h1>
<p class="date">2022-05-01</p>
</header>
<ol>
<li><p>Indicate which of the following best represents a <em>simplified guess</em> for a particular solution <span class="math inline">\(p(t)\)</span> to the non-homogeneous linear ODE: <span class="math display">\[(D-3)(D-1)x = te^{3t} + \cos(2t)\]</span></p>
<ol type="a">
<li><p><span class="math inline">\(p(t) = k_1 te^{3t} + k_2 \cos(2t) + k_3 \sin(2t)\)</span></p></li>
<li><p><span class="math inline">\(p(t) = k_1 te^{3t} + k_2 \cos(2t)\)</span></p></li>
<li><p><span class="math inline">\(p(t) = k_1 te^{3t} + k_2 t^2 e^{3t} + k_3 \cos(2t)\)</span></p></li>
<li><p><span class="math inline">\(p(t) = k_1 te^{3t} + k_2 t^2 e^{3t} + k_3 \cos(2t) + k_4 \sin(2t)\)</span></p></li>
</ol>
<div class="solution">
<p><strong>Solution:</strong></p>
<p>correct response was d.</p>
<hr />
</div></li>
<li><p>Indicate which of the following represents the general solution to the homogeneous linear ODE <span class="math inline">\((D^2 - 2D + 2)^2x = 0.\)</span></p>
<ol type="a">
<li><p><span class="math inline">\(h(t) = c_1 e^{-t}\cos(t) + c_2 e^{-t}\sin(t) + c_3 te^{-t}\cos(t) + c_4 te^{-t}\sin(t)\)</span></p></li>
<li><p><span class="math inline">\(h(t) = c_1 e^t\cos(t) + c_2 e^t\sin(t)\)</span></p></li>
<li><p><span class="math inline">\(h(t) = c_1 e^t\cos(t) + c_2 e^t\sin(t) + c_3 te^t\cos(t) + c_4 te^t\sin(t)\)</span></p></li>
<li><p><span class="math inline">\(h(t) = c_1 te^t\cos(t) + c_2 te^t\sin(t) + c_3 t^2e^t\cos(t) + c_4 t^2e^t\sin(t)\)</span></p></li>
</ol>
<div class="solution">
<p><strong>Solution:</strong></p>
<p>correct response was a.</p>
<hr />
</div></li>
<li><p>The matrix <span class="math inline">\(A = \begin{bmatrix} -2 &amp; 5 \\ -2 &amp; 4 \end{bmatrix}\)</span> has characteristic polynomial <span class="math inline">\(\lambda^2 - 2\lambda + 2\)</span> and thus its eigenvalues are <span class="math inline">\(\lambda = 1 + i\)</span> and <span class="math inline">\(\lambda = 1-i\)</span>.</p>
<p>Which of the following is an eigenvector for <span class="math inline">\(A\)</span>?</p>
<ol type="a">
<li><p><span class="math inline">\(A\)</span> has no eigenvectors.</p></li>
<li><p><span class="math inline">\(\begin{bmatrix} 3 - i \\ 2 \end{bmatrix}\)</span></p></li>
<li><p><span class="math inline">\(\begin{bmatrix} 2 \\ -3 + i \end{bmatrix}\)</span></p></li>
<li><p><span class="math inline">\(\begin{bmatrix} 3 + i \\ 2 \end{bmatrix}\)</span></p></li>
</ol>
<div class="solution">
<p><strong>Solution:</strong></p>
<p>correct response was d.</p>
<hr />
</div></li>
<li><p>Consider the linear system of ODEs <span class="math display">\[(\diamondsuit) \quad D \mathbf{x} =
\begin{bmatrix} 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 1 \\ 2 &amp; 1 &amp; 5 \end{bmatrix}
\mathbf{x} + \begin{bmatrix} 0 \\ 0 \\ e^t \end{bmatrix}.\]</span></p>
<p>A third order linear ODE is <em>equivalent</em> to this system if for each of its solutions <span class="math inline">\(x(t)\)</span>, the vector-valued function <span class="math inline">\(\mathbf{x}(t) = \begin{bmatrix} x(t) \\ x&#39;(t) \\ x&#39;&#39;(t) \end{bmatrix}\)</span> is a solution to <span class="math inline">\((\diamondsuit)\)</span>. Which of the following linear ODEs is equivalent to <span class="math inline">\((\diamondsuit)\)</span>?</p>
<ol type="a">
<li><p><span class="math inline">\((D^3 - 2D^2 - D - 5)x = e^t\)</span></p></li>
<li><p><span class="math inline">\((D^3 - 5D^2 - D - 2)x = e^t\)</span></p></li>
<li><p><span class="math inline">\((D^3 + 2D^2 + D + 5)x = -e^t\)</span></p></li>
<li><p><span class="math inline">\((D^3 + 5D^2 + D + 2)x = -e^t\)</span></p></li>
</ol>
<div class="solution">
<p><strong>Solution:</strong></p>
<p>correct response was b.</p>
<hr />
</div></li>
<li><p>Let <span class="math inline">\(A = \begin{bmatrix} 2 &amp; 0 &amp; 2 \\ 0 &amp; -1 &amp; 1 \\ 0 &amp; 0 &amp; 2\end{bmatrix}\)</span>. <span class="math inline">\(\lambda = 2\)</span> is an eigenvalue of <span class="math inline">\(A\)</span> with multiplicity two. The matrix <span class="math inline">\(A - 2\mathbf{I}_3\)</span> satisfies <span class="math inline">\((A-2\mathbf{I}_3)^2 = \begin{bmatrix} 0 &amp; 0 &amp; 2 \\ 0 &amp; -3 &amp; 1 \\ 0 &amp; 0 &amp; 0 \end{bmatrix}^2 = \begin{bmatrix} 0 &amp; 0 &amp; 0 \\ 0 &amp; 9 &amp; -3 \\ 0 &amp; 0 &amp; 0 \end{bmatrix} \sim \begin{bmatrix} 0 &amp; 3 &amp; -1 \\ 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 \end{bmatrix}.\)</span> Thus the generalized eigenvectors of <span class="math inline">\(A\)</span> for <span class="math inline">\(\lambda = 2\)</span> are generated by <span class="math inline">\(\mathbf{v} = \begin{bmatrix} 1 \\ 0 \\ 0 \end{bmatrix}\)</span> and <span class="math inline">\(\mathbf{w} = \begin{bmatrix} 0 \\ 1 \\ 3 \end{bmatrix}\)</span>.</p>
<p>Which of the following represents a solution <span class="math inline">\(\mathbf{h}(t)\)</span> to the system <span class="math inline">\(D \mathbf{x} = A \mathbf{x}\)</span> with the property that <span class="math inline">\(\mathbf{h}(0) = \begin{bmatrix} 1 \\ 2 \\ 6 \end{bmatrix}\)</span>?</p>
<ol type="a">
<li><p><span class="math inline">\(\mathbf{h}(t) = e^{2t} \begin{bmatrix} 1 \\ 2 \\ 6 \end{bmatrix}\)</span></p></li>
<li><p><span class="math inline">\(\mathbf{h}(t) = e^{2t} \begin{bmatrix} 1+ 12t \\ 2 \\ 6 \end{bmatrix}\)</span></p></li>
<li><p><span class="math inline">\(\mathbf{h}(t) = e^{2t} \begin{bmatrix} 1+ t \\ 2 \\ 6 \end{bmatrix}\)</span></p></li>
<li><p>No solution <span class="math inline">\(\mathbf{h}(t)\)</span> has the property that <span class="math inline">\(\mathbf{h}(0) = \begin{bmatrix} 1 \\ 2 \\ 6 \end{bmatrix}\)</span>.</p></li>
</ol>
<div class="solution">
<p><strong>Solution:</strong></p>
<p>correct response was b.</p>
<hr />
</div></li>
<li><p>Consider the homogeneous system <span class="math inline">\((\diamondsuit) \quad D \mathbf{x} = A \mathbf{x}\)</span> where <span class="math inline">\(A\)</span> is a <span class="math inline">\(3 \times 3\)</span> matrix, and let <span class="math inline">\(\mathbf{h}_1(t),\mathbf{h}_2(t)\)</span> be solutions to <span class="math inline">\((\diamondsuit)\)</span>. Which of the following statements is correct?</p>
<ol type="a">
<li><p><span class="math inline">\(\mathbf{h}_1(0)\)</span> and <span class="math inline">\(\mathbf{h}_2(0)\)</span> are <em>eigenvectors</em> for <span class="math inline">\(A\)</span>.</p></li>
<li><p>The system <span class="math inline">\((\diamondsuit)\)</span> has exactly two solutions.</p></li>
<li><p>If the vectors <span class="math inline">\(\mathbf{h}_1(0),\mathbf{h}_2(0)\)</span> are linearly independent, then the general solution to <span class="math inline">\((\diamondsuit)\)</span> is given by <span class="math inline">\(\mathbf{x}(t) = c_1\mathbf{h}_1(t) + c_2\mathbf{h}_2(t)\)</span>.</p></li>
<li><p>None of the above statements is correct.</p></li>
</ol>
<div class="solution">
<p><strong>Solution:</strong></p>
<p>correct response was d.</p>
<p>To see that <strong>a.</strong> is incorrect, consider solutions <span class="math inline">\(e^{\lambda t} \mathbf{v}\)</span> and <span class="math inline">\(e^{\mu t} \mathbf{w}\)</span> arising from eigenvectors <span class="math inline">\(\mathbf{v}\)</span> and <span class="math inline">\(\mathbf{w}\)</span>.</p>
<p>Then there is a solution <span class="math inline">\(h(t) = e^{\lambda t} \mathbf{v} + e^{\mu t} \mathbf{w}\)</span> but <span class="math inline">\(h(0) = \mathbf{v} + \mathbf{w}\)</span> which is not an eigenvector if <span class="math inline">\(\lambda \ne \mu\)</span>.</p>
<p><strong>b.</strong> in incorrect. Indeed, all linear combinations <span class="math inline">\(c_1\mathbf{h}_1(t) + c_2 \mathbf{h}_2(t)\)</span> are solutions, so there are always <em>infinitely many solutions.</em></p>
<p>Finally, <strong>c.</strong> is incorrect because for a <span class="math inline">\(3 \times 3\)</span> system the general solution is generated by three solutions with linearly independent initial vectors; two solutions are not enough.</p>
<hr />
</div></li>
<li><p>The matrix <span class="math inline">\(A = \begin{bmatrix} 1 &amp; 1 \\ 2 &amp; 2 \end{bmatrix}\)</span> has characteristic polynomial <span class="math inline">\(\lambda(\lambda - 3)\)</span> and hence has eigenvalues <span class="math inline">\(\lambda = 0\)</span> and <span class="math inline">\(\lambda = 3\)</span>. An eigenvector for <span class="math inline">\(\lambda =0\)</span> is given by <span class="math inline">\(\mathbf{v} = \begin{bmatrix} -1 \\ 1 \end{bmatrix}\)</span> and an eigenvector for <span class="math inline">\(\lambda = 3\)</span> is given by <span class="math inline">\(\mathbf{w} = \begin{bmatrix} 1 \\ 2 \end{bmatrix}\)</span>.</p>
<p>Find a particular solution <span class="math inline">\(\mathbf{p}(t)\)</span> for the system of linear ODEs <span class="math display">\[D \mathbf{x} = A \mathbf{x} + \begin{bmatrix} 0 \\ t
\end{bmatrix}.\]</span></p>
<div class="solution">
<p><strong>Solution:</strong></p>
<p>The general solution is generated by the solutions obtained from eigenvectors: <span class="math display">\[\mathbf{h}_1(t) = e^{0t}\begin{bmatrix} -1 \\ 1
\end{bmatrix} = \begin{bmatrix} -1 \\ 1 \end{bmatrix} \quad
\text{and} \quad \mathbf{h}_2(t) = e^{3t}\begin{bmatrix}1 \\ 2
\end{bmatrix}\]</span></p>
<p>To find a particular solution, form the Wronskian matrix <span class="math display">\[W = \begin{bmatrix} -1 &amp; e^{3t} \\
1 &amp; 2e^{3t} \end{bmatrix}\]</span> and notice that <span class="math inline">\(\det W = -3e^{3t}\)</span>.</p>
<p>A particular solution has the form <span class="math inline">\(\mathbf{p}(t) = c_1(t) \mathbf{h}_1(t) + c_2(t) \mathbf{h}_2(t)\)</span>, where the vector <span class="math inline">\(\mathbf{c} = \begin{bmatrix} c_1(t) \\ c_2(t) \end{bmatrix}\)</span> satisfies the matrix equations <span class="math display">\[W \mathbf{c}&#39; = \begin{bmatrix} 0 \\ t \end{bmatrix}.\]</span></p>
<p>Using Cramer’s Rule, we find that <span class="math display">\[c_1&#39;(t) = \dfrac{\det \begin{bmatrix} 0 &amp; e^{3t} \\
t &amp; 2e^{3t} \end{bmatrix}}{-3e^{3t}} = \dfrac{-te^{3t}}{-3e^{3t}} = \dfrac{t}{3}.\]</span></p>
<p><span class="math display">\[c_2&#39;(t) = \dfrac{\det \begin{bmatrix} -1 &amp; 0 \\
1 &amp; t \end{bmatrix}}{-3e^{3t}} = \dfrac{-t}{-3e^{3t}}= \dfrac{te^{-3t}}{3}\]</span></p>
<p>Now we integrate to find <span class="math inline">\(c_1(t)\)</span> and <span class="math inline">\(c_2(t)\)</span>:</p>
<p><span class="math display">\[c_1(t) = \int c_1&#39;(t) dt = \dfrac{1}{3} \int t dt = \dfrac{t^2}{6} + A.\]</span></p>
<p>For <span class="math inline">\(c_2\)</span> we integrate by parts with <span class="math inline">\(u = t, dv = e^{-3t}dt\)</span>:</p>
<p><span class="math display">\[c_2(t) = \int c_2&#39;(t) dt = \dfrac{1}{3} \int te^{-3t} dt
= \dfrac{1}{3} \left(\dfrac{-t}{3}e^{-3t} + \dfrac{1}{3} \int e^{-3t}dt \right)
=\dfrac{-1}{9}e^{-3t}\left(t + \dfrac{1}{3} \right) + B\]</span></p>
<p>We may take <span class="math inline">\(A=B=0\)</span> since we only seek a particular solution. This gives <span class="math display">\[\begin{align*}
\mathbf{p}(t) =&amp;
\dfrac{t^2}{6} \begin{bmatrix} -1 \\ 1
\end{bmatrix} + 
\dfrac{-1}{9}e^{-3t}\left(t + \dfrac{1}{3} \right) e^{3t}\begin{bmatrix}1 \\ 2
\end{bmatrix} \\
=&amp; \dfrac{t^2}{6} \begin{bmatrix} -1 \\ 1
\end{bmatrix} + 
\dfrac{-1}{9}\left(t + \dfrac{1}{3} \right)\begin{bmatrix}1 \\ 2
\end{bmatrix}
\end{align*}\]</span></p>
<hr />
</div></li>
<li><p>Let <span class="math inline">\(A = \begin{bmatrix} 0 &amp; 1 \\ -5 &amp; 4 \end{bmatrix}\)</span>.</p>
<p>The characteristic polynomial of <span class="math inline">\(A\)</span> is <span class="math inline">\(r^2 -4r +5\)</span> so the eigenvalues of <span class="math inline">\(A\)</span> are <span class="math inline">\(\lambda = 2 \pm i\)</span>.</p>
<p>Moreover, <span class="math inline">\(\mathbf{v} = \begin{bmatrix} 2-i\\ 5 \end{bmatrix}\)</span> is an eigenvector for <span class="math inline">\(\lambda = 2 + i\)</span>.</p>
<ol type="a">
<li>Find the general solution to <span class="math inline">\(D \mathbf{x} = A \mathbf{x}\)</span>.</li>
</ol>
<div class="solution">
<p><strong>Solution:</strong></p>
<p>The complex solution to (H) is <span class="math display">\[\begin{equation*}
e^{2t}(\cos t +i \sin t)\begin{bmatrix} 2-i\\5\end{bmatrix}
=e^{2t}\begin{bmatrix}
2\cos t+\sin t\\
5\cos t
\end{bmatrix}
+i e^{2t}\begin{bmatrix}
-\cos t+2\sin t\\
5\sin t
\end{bmatrix}
\end{equation*}\]</span> so the real and imaginary parts of this expression generate the general solution <span class="math display">\[\begin{equation*}
x(t)=C_{1}e^{2t}\begin{bmatrix}
2\cos t+\sin t\\
5\cos t
\end{bmatrix}
+C_{2 } e^{2t}\begin{bmatrix}
-\cos t+2\sin t\\
5\sin t
\end{bmatrix}.
\end{equation*}\]</span></p>
<hr />
</div>
<ol start="2" type="a">
<li>Solve the initial value problem <span class="math inline">\(D \mathbf{x} = A \mathbf{x}, \quad \mathbf{x}(0) = \begin{bmatrix} 1 \\ 1 \end{bmatrix}\)</span>.</li>
</ol>
<div class="solution">
<p><strong>Solution:</strong></p>
<p>The value at <span class="math inline">\(t=0\)</span> of the general solution given above is <span class="math display">\[\begin{equation*}
X(0)=C_{1}e^{0}\begin{bmatrix}
2\cos 0+\sin 0\\
5\cos 0
\end{bmatrix}
+C_{2 } e^{0}\begin{bmatrix}
-\cos 0+2\sin 0\\
5\sin 0
\end{bmatrix}
=C_{1}\begin{bmatrix}
2\\
5
\end{bmatrix}
+C_{2}\begin{bmatrix}
-1\\
0
\end{bmatrix};
\end{equation*}\]</span> setting this equal to the desired initial condition yields the system of equations  which can be solved by performing row operations on the augmented matrix <span class="math display">\[\begin{equation*}
\begin{bmatrix}
2&amp;-1&amp;|1\\
5&amp;0&amp;|1
\end{bmatrix},
\end{equation*}\]</span> or by using Cramer’s Rule, or simply by noting that the second equation says <span class="math inline">\(C_{1}=\frac{1}{5}\)</span>, and substituting into the first equation yields <span class="math inline">\(\frac{2}{5}-C_{2}=1\)</span> or <span class="math inline">\(C_{2}=-\frac{3}{5}\)</span>.</p>
<p>Thus the desired solution of (H) is <span class="math display">\[\begin{equation*}
X(t)=
\frac{1}{5}e^{2t}\begin{bmatrix}2\cos t+\sin t\\5\cos t\end{bmatrix}
-\frac{3}{4}e^{2t}\begin{bmatrix}-\cos t+2\sin t\\5\sin t\end{bmatrix}
=e^{2t}\begin{bmatrix}\cos t-\sin t\\\cos t-3\sin t\end{bmatrix}.
\end{equation*}\]</span></p>
<hr />
</div></li>
<li><p>Solve the initial value problem <span class="math inline">\((4D^2 - 4D + 1)x = 0, \quad x(2) = x&#39;(2) = e\)</span>.</p>
<div class="solution">
<p><strong>Solution:</strong></p>
<p>The polynomial <span class="math inline">\(4r^2 - 4r + 1\)</span> has root <span class="math inline">\(r=1/2\)</span> with multiplicity 2. Thus the general solution is given by <span class="math display">\[x(t) = c_1e^{t/2}  + c_2 te^{t/2}.\]</span></p>
<p>Note that <span class="math display">\[\begin{align*}
x&#39;(t) &amp;= D[x(t)] = \dfrac{c_1}{2}e^{t/2} + c_2e^{t/2}D[t] \\
&amp;= \dfrac{c_1}{2}e^{t/2} + c_2e^{t/2}(D+1/2)[t] \\
&amp;= \dfrac{c_1}{2}e^{t/2} + c_2e^{t/2}(1 + t/2)
\end{align*}\]</span></p>
<p>Now, we need <span class="math display">\[e= x(2) = c_1e + 2c_2e\]</span> and <span class="math display">\[e = x&#39;(2) = \dfrac{1}{2}e c_1 + 2ec_2\]</span></p>
<p>Thus we must solve the matrix equation <span class="math display">\[\begin{bmatrix} e &amp; 2e \\ e/2 &amp; 2e \end{bmatrix}
\begin{bmatrix} c_1 \\ c_2 \end{bmatrix} =
\begin{bmatrix} e \\ e \end{bmatrix}\]</span></p>
<p>This can be solved in several ways – e.g. by row operations on the augmented matrix, as follows:</p>
<p><span class="math display">\[\begin{align*}
\left[
\begin{array}{c|c}
\begin{matrix} e &amp; 2e \\ e/2 &amp; 2e \end{matrix} &amp;
\begin{matrix} e \\ e \end{matrix}
\end{array}
\right]
\sim 
\left[
\begin{array}{c|c}
\begin{matrix} 1 &amp; 2 \\ 1 &amp; 4 \end{matrix} &amp;
\begin{matrix} 1 \\ 2 \end{matrix}
\end{array}
\right]  
\sim 
\left[
\begin{array}{c|c}
\begin{matrix} 1 &amp; 2 \\ 0 &amp; 2 \end{matrix} &amp;
\begin{matrix} 1 \\ 1 \end{matrix}
\end{array}
\right]     
\sim 
\left[
\begin{array}{c|c}
\begin{matrix} 1 &amp; 0 \\ 0 &amp; 2 \end{matrix} &amp;
\begin{matrix} 0 \\ 1 \end{matrix}
\end{array}
\right]        
\end{align*}\]</span></p>
<p>Thus <span class="math inline">\(c_1 =0\)</span> and <span class="math inline">\(c_2 = 1/2\)</span> so that the solution to the initial value problem is given by <span class="math display">\[x(t) = \dfrac{te^{t/2}}{2}.\]</span></p>
<hr />
</div></li>
<li><p>Consider the matrix <span class="math inline">\(B = \begin{bmatrix} 5 &amp; -3 &amp; -6 \\ 0 &amp; 2 &amp; 0 \\ 3 &amp; -3 &amp; -4 \end{bmatrix}\)</span>.</p>
<ol type="a">
<li><p>The vector <span class="math inline">\(\mathbf{v} = \begin{bmatrix} 1 \\ -1 \\ 1 \end{bmatrix}\)</span> is an eigenvector for <span class="math inline">\(B\)</span>. What is the corresponding eigenvalue?</p>
<p><strong>Hint:</strong> Compute the vector <span class="math inline">\(B \mathbf{v}\)</span> and compare with <span class="math inline">\(\mathbf{v}\)</span>.</p></li>
</ol>
<div class="solution">
<p><strong>Solution:</strong></p>
<p>The product <span class="math inline">\(B \mathbf{v}\)</span> is equal to <span class="math display">\[B\mathbf{v} =
\begin{bmatrix} 2 \\ -2 \\ 2 \end{bmatrix} = 2 \begin{bmatrix} 1 \\
-1 \\ 1 \end{bmatrix} = 2 \mathbf{v}\]</span> so the eigenvalue is <span class="math inline">\(\lambda = 2\)</span>.</p>
<hr />
</div>
<ol start="2" type="a">
<li>Find an eigenvector for <span class="math inline">\(B\)</span> for the eigenvalue <span class="math inline">\(\lambda = -1\)</span>.</li>
</ol>
<div class="solution">
<p><strong>Solution:</strong> Perform row operations on the matrix <span class="math inline">\(B - (-1)\mathbf{I}_3 = B + \mathbf{I_3}\)</span>:</p>
<p><span class="math display">\[\begin{align*}
\begin{bmatrix}
6 &amp; -3 &amp; -6 \\ 0 &amp; 3 &amp; 0 \\ 3 &amp; -3 &amp; -3
\end{bmatrix}
\sim 
\begin{bmatrix}
2 &amp; -1 &amp; -2 \\ 0 &amp; 1 &amp; 0 \\ 1 &amp; -1 &amp; -1
\end{bmatrix}   
\sim 
\begin{bmatrix}
0 &amp; 1 &amp; 0 \\ 0 &amp; 1 &amp; 0 \\ 1 &amp; -1 &amp; -1
\end{bmatrix}      
\sim 
\begin{bmatrix}
1 &amp; -1 &amp; -1 \\ 0 &amp; 1 &amp; 0 \\  0 &amp; 0 &amp; 0 
\end{bmatrix}         
\sim 
\begin{bmatrix}
1 &amp; 0 &amp; -1 \\ 0 &amp; 1 &amp; 0 \\  0 &amp; 0 &amp; 0 
\end{bmatrix}            
\end{align*}\]</span></p>
<p>Considering this echelon matrix, we see that an eigenvector for <span class="math inline">\(\lambda = -1\)</span> is given by <span class="math display">\[\begin{bmatrix} 1 \\ 0 \\ 1
\end{bmatrix}.\]</span></p>
<hr />
</div></li>
<li><p>Laplace Transforms:</p>
<ol type="a">
<li>Compute the inverse Laplace tranform <span class="math inline">\(\mathscr{L}^{-1}[F(s)]\)</span> of the function <span class="math inline">\(F(s) = \dfrac{3s^2+s+1}{(s+1)(s^2 + 2)}\)</span>.</li>
</ol>
<div class="solution">
<p><strong>Solution:</strong></p>
<p>The partial fraction decomposition has the form <span class="math display">\[\begin{equation*}
\frac{3s^{2}+s+1}{(s+1)(s^{2}+2)}=\frac{A}{s+1}+\frac{Bs+C}{s^{2}+2};
\end{equation*}\]</span> combining over a common denominator and matching coefficients leads to <span class="math display">\[\begin{equation*} \begin{array}{lrrrcr} s^{2}
\text{ terms}:&amp;A&amp;+B&amp;&amp;=&amp;3\\ s \text{ terms}:&amp;&amp;B&amp;+C&amp;=&amp;1\\
\text{constant terms}:&amp;2A&amp;&amp;+C&amp;=&amp;1 \end{array} \end{equation*}\]</span> We can solve the first (respectively, second) equation for <span class="math inline">\(A\)</span> (respectively, <span class="math inline">\(C\)</span>) in terms of <span class="math inline">\(B\)</span>: <span class="math display">\[\begin{align*} A&amp;=3-B\\ C&amp;=1-B
\end{align*}\]</span> and substituting into the third equation yields <span class="math display">\[\begin{align*} (6-2B)+(1-B)&amp;=1\\ -3B&amp;=-6\\ B&amp;=2\\ A&amp;=1\\ C&amp;=-1
\end{align*}\]</span> so <span class="math display">\[\begin{equation*}
\frac{3s^{2}+s+1}{(s+1)(s^{2}+2)}=\frac{1}{s+1}+\frac{2s-1}{s^{2}+2}.
\end{equation*}\]</span> Then the inverse transform is <span class="math display">\[\begin{align*}
{\mathscr{L}}^{-1}\left[\frac{3s^{2}+s+1}{(s+1)(s^{2}+2)}\right]&amp;=%\\
{\mathscr{L}}^{-1}\left[\frac{1}{s+1}
\right]+{\mathscr{L}}^{-1}\left[
\frac{2s}{s^{2}+2}\right]-{\mathscr{L}}^{-1}\left[\frac{1}{s^{2}+2}
\right]\\ &amp;=e^{-t}+2\cos t\sqrt{2} -\frac{1}{\sqrt{2}}\sin
t\sqrt{2}.  \end{align*}\]</span></p>
<hr />
</div>
<ol start="2" type="a">
<li>If <span class="math inline">\(x\)</span> is a solution to <span class="math inline">\((D^2 + D + 1)x = 1\)</span> with <span class="math inline">\(x(0) = 0\)</span> and <span class="math inline">\(x&#39;(0) = 1\)</span>, find an expression for <span class="math inline">\(\mathscr{L}[x]\)</span> as a function of <span class="math inline">\(s\)</span>.</li>
</ol>
<div class="solution">
<p><strong>Solution:</strong></p>
<p>By the first differentiation formula, applying the Laplace Transform to both sides of the problem yields <span class="math display">\[\begin{align*}
\mathscr{L}{D^{2}x}+\mathscr{L}{Dx}+\mathscr{L}{x}&amp;=\mathscr{L}{1}\\
\lbrace s^{2}\mathscr{L}{x}-s x(0)-x&#39;(0)\rbrace +\lbrace
s\mathscr{L}{x}-x(0)\rbrace+\mathscr{L}{x} &amp;=\mathscr{L}{1}\\
s^{2}\mathscr{L}{x}-1 +s\mathscr{L}{x}+\mathscr{L}{x}
&amp;=\frac{1}{s}\\
(s^{2}+s+1)\mathscr{L}{x}&amp;=1+\frac{1}{s}=\frac{1+s}{s}\\
\mathscr{L}{x}&amp;=\frac{1+s}{s(s^{2}+2+1)} \end{align*}\]</span></p>
<hr />
</div></li>
<li><p>Let <span class="math inline">\(W = W(h_1(t),h_2(t))\)</span> denote the <em>Wronskian matrix</em> of the functions <span class="math inline">\(h_1(t) = e^{2t}\)</span> and <span class="math inline">\(h_2(t) = te^{2t}\)</span>. Which of the following represents the <em>determinant</em> of <span class="math inline">\(W\)</span>?</p>
<ol type="a">
<li><p><span class="math inline">\(e^{4t}\)</span></p></li>
<li><p><span class="math inline">\((1+4t)e^{4t}\)</span></p></li>
<li><p><span class="math inline">\(e^{2t}\)</span></p></li>
<li><p><span class="math inline">\((1+4t)e^{2t}\)</span></p></li>
</ol>
<div class="solution">
<p><strong>Solution:</strong></p>
<p>correct answer is c.</p>
<hr />
</div></li>
<li><p>Consider the vectors <span class="math inline">\(\mathbf{v}_1 = \begin{bmatrix} -1 \\ 1 \\ 0 \\ 0 \end{bmatrix}\)</span>, <span class="math inline">\(\mathbf{v}_2 = \begin{bmatrix} -1 \\ 1 \\ 0 \\ 1 \end{bmatrix}\)</span>, and <span class="math inline">\(\mathbf{v}_3 = \begin{bmatrix} 1 \\ 1 \\ 0 \\ 2\end{bmatrix}\)</span> in <span class="math inline">\(\mathbf{R}^4\)</span>, and let <span class="math inline">\(A = \begin{bmatrix} -1 &amp; -1 &amp; 1 \\ 1 &amp; 1 &amp; 1 \\ 0 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 2 \end{bmatrix}\)</span> be the <span class="math inline">\(4 \times 3\)</span> matrix whose columns are the <span class="math inline">\(\mathbf{v}_i\)</span>. Which of the following statements is correct?</p>
<ol type="a">
<li><p>The vectors <span class="math inline">\(\mathbf{v}_1,\mathbf{v}_2,\mathbf{v}_3\)</span> are <em>linearly dependent</em>.</p></li>
<li><p>Since <span class="math inline">\(A \sim \begin{bmatrix} 1 &amp; 1 &amp; -1 \\ 0 &amp; 1 &amp; 2 \\ 0 &amp; 0 &amp; 2 \\ 0 &amp; 0 &amp; 0 \end{bmatrix}\)</span>, the only solution to the equation <span class="math inline">\(A \mathbf{w} = \mathbf{0}\)</span> is <span class="math inline">\(\mathbf{w} = \mathbf{0}\)</span> so the vectors <span class="math inline">\(\mathbf{v}_1,\mathbf{v}_2,\mathbf{v}_3\)</span> are <em>linearly independent</em>.</p></li>
<li><p>The equation <span class="math inline">\(A \mathbf{w} = \mathbf{x}\)</span> has a solution for every vector <span class="math inline">\(\mathbf{x}\)</span> in <span class="math inline">\(\mathbf{R}^4\)</span>.</p></li>
<li><p>The determinant of <span class="math inline">\(A\)</span> is <span class="math inline">\(\ne 0\)</span>.</p></li>
</ol>
<div class="solution">
<p><strong>Solution:</strong></p>
<p>The correct response is b.</p>
<p>Answer a. is incorrect because the vectors are independent.</p>
<p>Answer c. is incorrect because the given equation has no solution when <span class="math inline">\(\mathbf{x} = \begin{bmatrix} 0 \\ 0 \\ 0 \\ 1 \end{bmatrix}\)</span>.</p>
<p>Answer d. is incorrect because the determinant of a <span class="math inline">\(4 \times 3\)</span> (non-square!) matrix is not defined.</p>
<hr />
</div></li>
<li><p>Let <span class="math inline">\(A\)</span> be an <span class="math inline">\(n \times n\)</span> matrix with constant coefficients <span class="math inline">\(a_{ij}\)</span>, and let <span class="math inline">\(\mathbf{E}(t)\)</span> be a vector with <span class="math inline">\(n\)</span> components. If <span class="math inline">\(\mathbf{v}\)</span> is any vector in <span class="math inline">\(\mathbf{R}^n\)</span>, must there be a solution <span class="math inline">\(\mathbf{x}(t)\)</span> to the system of equations <span class="math inline">\(D\mathbf{x} = A \mathbf{x} + \mathbf{E}(t)\)</span> for which <span class="math inline">\(\mathbf{x}(0) = \mathbf{v}\)</span>?</p>
<ol type="a">
<li><p>No, this conclusion is only guaranteed when the system is <em>homogeneous</em>.</p></li>
<li><p>No, this conclusion is only guaranteed when the entries of the vector <span class="math inline">\(\mathbf{E}(t)\)</span> are <em>constant</em> functions of <span class="math inline">\(t\)</span>.</p></li>
<li><p>Yes, this conclusion is the content of the <em>Existence and Uniqueness Theorem for Solutions of Linear Systems</em>.</p></li>
<li><p>No, this conclusion is only guaranteed when <span class="math inline">\(\det A \ne 0\)</span>.</p></li>
</ol>
<div class="solution">
<p><strong>Solution:</strong></p>
<p>correct response is c.</p>
<p>The existence and uniqueness theorem applies for non-homogeneous systems (so a is incorrect) and applies so long as the entries of <span class="math inline">\(A\)</span> and of <span class="math inline">\(\mathbf{E}\)</span> are <em>continuous</em> functions of <span class="math inline">\(t\)</span> (so b. is incorrect). Finally, the existence and uniqueness theorem is valid even when <span class="math inline">\(A\)</span> has determinant <span class="math inline">\(0\)</span> (so d. is incorrect).</p>
<hr />
</div></li>
<li><p>Consider the homogeneous system <span class="math inline">\((\diamondsuit) \quad D \mathbf{x} = A \mathbf{x}\)</span> where <span class="math inline">\(A\)</span> is a <span class="math inline">\(3 \times 3\)</span> matrix.</p>
<ol type="a">
<li>If <span class="math inline">\(\mathbf{h}(t)\)</span> is a solution, must <span class="math inline">\(\mathbf{h}(0)\)</span> be an eigenvector for <span class="math inline">\(A\)</span>? Why or why not?</li>
</ol>
<div class="solution">
<p><strong>Solution:</strong></p>
<p>No, <span class="math inline">\(\mathbf{h}(0)\)</span> need not be an eigenvector. Suppose for example that <span class="math inline">\(\mathbf{v}\)</span> and <span class="math inline">\(\mathbf{w}\)</span> are eigenvectors for <span class="math inline">\(A\)</span> with eigenvalues <span class="math inline">\(\lambda, \mu\)</span>, and suppose that <span class="math inline">\(\lambda \ne \mu\)</span>. Then <span class="math inline">\(\mathbf{v} + \mathbf{w}\)</span> is not an eigenvector.</p>
<p>Indeed, since <span class="math inline">\(\lambda \ne \mu\)</span> we know that <span class="math inline">\(\mathbf{v}\)</span> and <span class="math inline">\(\mathbf{w}\)</span> are <em>linearly independent</em>. Now, for any number <span class="math inline">\(\beta\)</span>, <span class="math display">\[(A-\beta \mathbf{I})(\mathbf{v} + \mathbf{w}) =
(\lambda - \beta) \mathbf{v} + (\mu - \beta) \mathbf{w}\]</span> Since <span class="math inline">\(\lambda \ne \mu\)</span>, at least one of <span class="math inline">\(\lambda - \beta\)</span> or <span class="math inline">\(\mu - \beta\)</span> is non-zero, so the linear independence of <span class="math inline">\(\mathbf{v}\)</span> and <span class="math inline">\(\mathbf{w}\)</span> shows that <span class="math inline">\((A-\beta \mathbf{I})(\mathbf{v} + \mathbf{w})\)</span> is non-zero. This shows that <span class="math inline">\(\mathbf{v} + \mathbf{w}\)</span> is not an eigenvector (for <em>any</em> eigenvalue <span class="math inline">\(\beta\)</span>).</p>
<p>Now, the function <span class="math display">\[h(t) = e^{\lambda t} \mathbf{v} + e^{\mu t}
\mathbf{w}\]</span> is a solution to <span class="math inline">\((\diamondsuit)\)</span>, and <span class="math inline">\(h(0) = \mathbf{v} + \mathbf{w}\)</span>.</p>
<hr />
</div>
<ol start="2" type="a">
<li>Show that the vectors <span class="math inline">\(\begin{bmatrix} 1 \\ 0 \\ 1\end{bmatrix}\)</span>, <span class="math inline">\(\begin{bmatrix} -1 \\ 2 \\ 1 \end{bmatrix}\)</span>, and <span class="math inline">\(\begin{bmatrix} 1 \\ 2 \\ 1 \end{bmatrix}\)</span> are linearly dependent.</li>
</ol>
<div class="solution">
<p><strong>Solution:</strong></p>
<p>We perform row operations on the matrix whose columns are given by these vectors: <span class="math display">\[
\begin{bmatrix} 1 &amp; -1 &amp; 1 \\ 0 &amp; 2 &amp; 2 \\ 1 &amp; 1 &amp;
1 \end{bmatrix} \sim 
\begin{bmatrix} 1 &amp; -1 &amp; 1 \\ 0 &amp; 2 &amp; 2 \\ 0 &amp; 2 &amp;
0 \end{bmatrix} 
\sim 
\begin{bmatrix} 1 &amp; -1 &amp; 1 \\ 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp;
1 \end{bmatrix} 
\]</span></p>
<p>Since the resulting echelon matrix has 3 pivots and no free variables, the only solution <span class="math inline">\(\mathbf{c}\)</span> to the matrix equation <span class="math display">\[\begin{bmatrix} 1 &amp; -1 &amp; 1 \\ 0 &amp; 2 &amp; 2 \\ 1 &amp; 1 &amp; 1
\end{bmatrix} \cdot \begin{bmatrix} c_1 \\ c_2 \\ c_3 \end{bmatrix}
= \begin{bmatrix} 0 \\ 0 \\ 0 \end{bmatrix}\]</span> is <span class="math inline">\(\mathbf{c} = \begin{bmatrix} c_1 \\ c_2 \\ c_3 \end{bmatrix} = \mathbf{0}\)</span>. (Alternatively, you could have obtained this conclusion by noting that the <em>determinant</em> of the matrix <span class="math inline">\(\begin{bmatrix} 1 &amp; -1 &amp; 1 \\ 0 &amp; 2 &amp; 2 \\ 1 &amp; 1 &amp; 1 \end{bmatrix}\)</span> is equal to <span class="math inline">\(0\)</span>).</p>
<p>Thus the only coefficients satisfying the following equation <span class="math display">\[c_1
\begin{bmatrix} 1 \\ 0 \\ 1\end{bmatrix} + c_2 \begin{bmatrix} -1
\\ 2 \\ 1 \end{bmatrix}
+ c_3\begin{bmatrix} 1 \\ 2 \\ 1 \end{bmatrix} = \mathbf{0}\]</span> are <span class="math inline">\(c_1 = c_2 = c_3 = 0\)</span>; this shows that the vectors are linearly independent.</p>
<hr />
</div>
<ol start="3" type="a">
<li>Let <span class="math inline">\(\mathbf{h}_1(t),\mathbf{h}_2(t),\mathbf{h}_3(t)\)</span> be solutions to <span class="math inline">\((\diamondsuit)\)</span>. Suppose that <span class="math inline">\(\mathbf{h}_1(0) = \begin{bmatrix} 1 \\ 0 \\ 1\end{bmatrix}\)</span>, <span class="math inline">\(\mathbf{h}_2(0) = \begin{bmatrix} -1 \\ 2 \\ 1 \end{bmatrix}\)</span>, and <span class="math inline">\(\mathbf{h}_3(0) = \begin{bmatrix} 1 \\ 2 \\ 1 \end{bmatrix}\)</span> are the vectors from b. Do the solutions <span class="math inline">\(\mathbf{h}_1(t),\mathbf{h}_2(t),\mathbf{h}_3(t)\)</span> generate the general solution to <span class="math inline">\((\diamondsuit)\)</span>? Why or why not?</li>
</ol>
<div class="solution">
<p><strong>Solution:</strong></p>
<p>Yes. Since <span class="math inline">\(A\)</span> is a <span class="math inline">\(3 \times 3\)</span> matrix, one knows that three solutions <span class="math inline">\(\mathbf{h}_1(t)\)</span>, <span class="math inline">\(\mathbf{h}_2(t)\)</span> and <span class="math inline">\(\mathbf{h}_3(t)\)</span> generate the general solution provided that the “initial vectors” <span class="math inline">\(\mathbf{h}_1(0),\mathbf{h}_2(0),\mathbf{h}_3(0)\)</span> are linearly independent; thus the result in part b. shows that the <span class="math inline">\(\mathbf{h}_i(t)\)</span> generate the general solution.</p>
<hr />
</div></li>
<li><p>A drug is absorbed by the body at a rate proportional to the amount of the drug present in the bloodstream after <span class="math inline">\(t\)</span> hours. If there are <span class="math inline">\(x(t)\)</span> mg of the drug present in the bloodstream at time <span class="math inline">\(t\)</span>, assume that the drug is absorbed at a rate of <span class="math inline">\(0.5 x(t)\)</span> /hour. If a patient receives the drug intravenously at a constant rate of 3 mg/hour, to which of the following ODEs is <span class="math inline">\(x(t)\)</span> a solution?</p>
<ol type="a">
<li><p><span class="math inline">\(x&#39;(t) = -0.5x(t) + 3\)</span></p></li>
<li><p><span class="math inline">\(x&#39;(t) = -0.5x(t); \quad x(0) = 3\)</span></p></li>
<li><p><span class="math inline">\(x&#39;(t) = 0.5x(0) + 3\)</span></p></li>
<li><p><span class="math inline">\(x&#39;(t) = .5x(t) - 3\)</span></p></li>
</ol>
<div class="solution">
<p><strong>Solution:</strong></p>
<p>correct response is a.</p>
<hr />
</div></li>
<li><p>You are given that a particular solution to <span class="math display">\[(\heartsuit) \quad (D^2-2D +1)x = e^t\]</span> is <span class="math inline">\(p(t) = \dfrac{t^2 e^t}{2}\)</span>. Which of the following best represents the general solution to <span class="math inline">\((\heartsuit)\)</span>?</p>
<ol type="a">
<li><p><span class="math inline">\(c_1 e^t + c_2 te^t\)</span>.</p></li>
<li><p><span class="math inline">\(\dfrac{t^2 e^t}{2} + c_1 e^t + c_2 te^t\)</span>.</p></li>
<li><p><span class="math inline">\(\dfrac{t^2 e^t}{2} + c e^t\)</span>.</p></li>
<li><p><span class="math inline">\(\dfrac{t^2 e^t}{2} + c_1 e^t + c_2 e^{-t}\)</span>.</p></li>
</ol>
<div class="solution">
<p><strong>Solution:</strong></p>
<p>correct response was b.</p>
<hr />
</div></li>
<li><p>Let <span class="math inline">\(x_1(t)\)</span> and <span class="math inline">\(x_2(t)\)</span> be solutions to the ODE <span class="math inline">\((t+1)x&#39;&#39; + x&#39; + x = 0\)</span>. Suppose that <span class="math inline">\(x_1(0) = x_2(0)\)</span> and that <span class="math inline">\(x_1&#39;(0) = x_2&#39;(0)\)</span>. Which of the following statements must be correct?</p>
<ol type="a">
<li><p><span class="math inline">\(x_1(t) = x_2(t)\)</span> for every <span class="math inline">\(t\)</span>.</p></li>
<li><p>Since the ODE is <em>normal</em> on the interval <span class="math inline">\((-1,\infty)\)</span>, we can conclude that <span class="math inline">\(x_1(t) = x_2(t)\)</span> for <span class="math inline">\(-1 &lt; t &lt; \infty\)</span>.</p></li>
<li><p>No conclusion is possible because the existence and uniqueness theorem does not apply to this ODE.</p></li>
<li><p>We can only conclude that <span class="math inline">\(x_1(t) = x_2(t)\)</span> for all <span class="math inline">\(t\)</span> if we also assume that <span class="math inline">\(x&#39;&#39;_1(0) = x&#39;&#39;_2(0)\)</span>.</p></li>
</ol>
<div class="solution">
<p><strong>Solution:</strong></p>
<p>correct response was b. Indeed since the equation is of 2nd order and since it is normal on the interval <span class="math inline">\((-1,\infty)\)</span>, the existence and uniqueness theorem guarantees for any <span class="math inline">\(\alpha,\beta\)</span> that there is only one solution <span class="math inline">\(x\)</span> which <span class="math inline">\(x(0) = \alpha\)</span> and <span class="math inline">\(x&#39;(0) = \beta\)</span>.</p>
<p>Assertion a. need not be true since the ODE is not normal on <span class="math inline">\((-\infty,\infty)\)</span>.</p>
<p>And assertion d. is incorrect – the existence and uniqueness theorem doesn’t require a condition on the second derivative in this case.</p>
<hr />
</div></li>
<li><p>Show that the functions <span class="math display">\[f_1(t) = e^t\cos(t), \quad
f_2(t) = e^t\sin(t), \quad f_3(t) = e^t\]</span> are linearly independent.</p>
<p>You have been told that functions like this are independent. However, here we want you to demonstrate it directly in this case. You may use the <em>Wronskian test</em> (with all details needed to justify using it) or other, direct arguments from the definition.</p>
<div class="solution">
<p><strong>Solution:</strong></p>
<p>There are several possible strategies for solving this problem; here we list a few of them.</p>
<p>First, you can use the Wronskian test. This requires computation of the first and second derivatives of the <span class="math inline">\(f_i\)</span>, which is perhaps most easily done using the <em>exponential shift formula</em>.</p>
<p>One finds: <span class="math display">\[D[e^t\cos(t)] = e^t(D+1)[\cos(t)] = e^t(\cos(t) - \sin(t))\]</span> <span class="math display">\[D[e^t\sin(t)] = e^t(D+1)[\sin(t)] = e^t(\cos(t) + \sin(t))\]</span> <span class="math display">\[D^2[e^t\cos(t)] = D[e^t(\cos(t) - \sin(t))] = e^t(D+1)[\cos(t) - \sin(t)] = -2e^t \sin(t).\]</span> <span class="math display">\[D^2[e^t\sin(t)] = D[e^t(\cos(t) + \sin(t))] = e^t(D+1)[\cos(t) + \sin(t)] = 2e^t \cos(t).\]</span></p>
<p>Thus the Wronskian matrix is given by <span class="math display">\[W = W(f_1,f_2,f_3) = \begin{bmatrix}
e^t \cos(t) &amp; e^t \sin(t) &amp; e^t \\
e^t(\cos(t) - \sin(t)) &amp; e^t(\cos(t) + \sin(t)) &amp; e^t \\
-2e^t\sin(t) &amp; 2e^t \cos(t) &amp; e^t
\end{bmatrix}\]</span></p>
<p>Now, according to the Wronskian test, the functions will be linearly independent (on the interval <span class="math inline">\((-\infty,\infty)\)</span>) provided that <span class="math inline">\(\det W(t_0)\)</span> is non-zero for some <span class="math inline">\(t_0\)</span>. If we take <span class="math inline">\(t_0 = 0\)</span>, we find that</p>
<p><span class="math display">\[\det W\bigg \vert_{t=0} = \det \begin{bmatrix}
1 &amp; 0 &amp; 1 \\
1 &amp; 1 &amp; 1 \\
0 &amp; 2 &amp; 1
\end{bmatrix} = \det \begin{bmatrix}
1 &amp; 1 \\ 
2 &amp; 1
\end{bmatrix} + \det \begin{bmatrix}
1 &amp; 1 \\
0 &amp; 2
\end{bmatrix} = -1 + 2 = 1\]</span></p>
<p>Since this determinant is non-zero, the Wronskian test confirms the linear independence of <span class="math inline">\(f_1,f_2,f_3\)</span>.</p>
<hr />
<p>A second method of solving this problem just uses the <em>definition of linear independence.</em></p>
<p>Suppose that <span class="math inline">\(c_1,c_2,c_3\)</span> are constants and that <span class="math display">\[c_1 e^t
\cos(t) + c_2 e^t \sin(t) + c_2 e^t = 0.\]</span> To show that the functions are linearly independent, we must <em>argue</em> that <span class="math inline">\(c_1 = c_2 = c_3 = 0\)</span>.</p>
<p>Factoring out the quantity <span class="math inline">\(e^t\)</span>, our assumption shows that <span class="math display">\[e^t(c_1\cos(t) + c_2\sin(t) + c_3)  = 0.\]</span> Since <span class="math inline">\(e^t \ne 0\)</span> for all <span class="math inline">\(t\)</span>, we find that <span class="math display">\[c_1\cos(t) + c_2\sin(t) + c_3  = 0.\]</span></p>
<p>Now, since this equation holds for all times <span class="math inline">\(t\)</span>, we may choose some particular values of <span class="math inline">\(t\)</span> to find equations for the constants <span class="math inline">\(c_i\)</span>.</p>
<p>When <span class="math inline">\(t=0\)</span>, we find that <span class="math display">\[0 = c_1 \cos(0) + c_2\sin(0) + c_3 = c_1 + c_3.\]</span></p>
<p>When <span class="math inline">\(t=\pi/2\)</span>, we find that <span class="math display">\[0 = c_1 \cos(\pi/2) + c_2\sin(\pi/2) + c_3 = c_2 + c_3.\]</span></p>
<p>When <span class="math inline">\(t=\pi\)</span>, we find that <span class="math display">\[0 = c_1 \cos(\pi) + c_2\sin(\pi) + c_3 = -c_1 + c_3.\]</span></p>
<p>Now, we solve the system of equations <span class="math display">\[\begin{align*}
0 &amp;= c_1 + c_3 \\
0 &amp;= c_2 + c_3 \\
0 &amp;= -c_1 + c_3 \\   
\end{align*}\]</span></p>
<p>Adding the first and third equation gives <span class="math inline">\(0 = 2c_3\)</span> so that <span class="math inline">\(c_3 = 0\)</span>. Now the first equation shows that <span class="math inline">\(c_1 = 0\)</span> and the second shows that <span class="math inline">\(c_2 = 0\)</span>.</p>
<p>Since we have argued that <span class="math inline">\(c_1=c_2=c_3=0\)</span>, we conclude from the definition that <span class="math inline">\(f_1,f_2,f_3\)</span> are linearly independent.</p>
<hr />
</div></li>
<li><p>Find the Laplace transform of the function <span class="math display">\[\begin{equation*}
f(t)=\left\{ 
\begin{array}{ll}
1 &amp; \text{ for } t&lt;1, \\
t-1 &amp; \text{ for } 1\leq t&lt;2, \\
1 &amp; \text{ for }t\geq 2.
\end{array}\right .
\end{equation*}\]</span></p>
<div class="solution">
<p><strong>Solution:</strong></p>
<p>In order to be able to compute the Laplace transform, We first rewrite the function <span class="math inline">\(f(t)\)</span> using the <em>unit step functions</em>.</p>
<p>We have <span class="math display">\[\begin{align*}
f(t) &amp;= 1 + u_1(t)\cdot(-1 + (t-1)) + u_2(t)\cdot((-(t-1) + 1) \\
&amp;= 1 + u_1(t)\cdot (t-2) + u_2(t)\cdot(-t +2).
\end{align*}\]</span></p>
<p>Thus <span class="math display">\[\begin{align*}
\mathscr{L}[f(t)]  &amp;= \mathscr{L}[1 + u_1(t)\cdot (t-2) + u_2(t)\cdot(-t +2)] \\
&amp;= \mathscr{L}[1] + \mathscr{L}[u_1(t)\cdot (t-2)] + \mathscr{L}[u_2(t)\cdot(-t +2)] \\
&amp;= \mathscr{L}[1] + e^{-s}\mathscr{L}[(t+1) - 2] + e^{-2s} \mathscr{L}[-(t+2) +2] \\
&amp;= \mathscr{L}[1] + e^{-s}\mathscr{L}[t-1] + e^{-2s} \mathscr{L}[-t] \\   
&amp;= (1 - e^{-s})\mathscr{L}[1] +  e^{-s}\mathscr{L}[t] - e^{-2s} \mathscr{L}[t] \\ 
&amp;= (1 - e^{-s})\mathscr{L}[1] +  (e^{-s} - e^{-2s})\mathscr{L}[t] \\
&amp;= \dfrac{1 - e^{-s}}{s} + \dfrac{e^{-s} - e^{-2s}}{s^2} \\
\end{align*}\]</span></p>
<hr />
<p>`</p>
</div></li>
<li><p>Suppose <span class="math inline">\(g(t)\)</span> is the inverse Laplace transform of <span class="math display">\[\begin{equation*}
F(s)=\frac{2se^{\pi s/2}}{(s^{2}+4)}.
\end{equation*}\]</span> Find <span class="math inline">\(g\left(\dfrac{\pi}{4}\right)\)</span>.</p>
<div class="solution">
<p><strong>Solution:</strong></p>
<p>We use the <em>second shift formula</em> to find <span class="math inline">\(g(t)\)</span>. Notice that if we set <span class="math display">\[f(t) = \mathscr{L}^{-1}\left[\dfrac{s}{s^2 + 4}\right] = 
\cos(2t)\]</span> then the second shift formula yields</p>
<p><span class="math display">\[\begin{align*}
g(t) &amp;= \mathscr{L}^{-1}[F(s)] =
2\mathscr{L}^{-1}\left[e^{(\pi/2)s} \dfrac{s}{s^2+4}\right]  \\
&amp;= 2 u_{\pi/2}(t)f(t-\pi/2)
\end{align*}\]</span></p>
<p>Thus <span class="math inline">\(u_{\pi/2}(\pi/4) = 0\)</span> so that <span class="math inline">\(g(\pi/4) = 2u_{\pi/2}(\pi/4) \cdot f(\pi/4 - \pi/2) = 0\)</span>.</p>
<hr />
</div></li>
</ol>
</body>
</html>
